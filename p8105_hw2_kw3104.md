p8105_hw2_kw3104
================

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
library(dplyr)
```

## Problem 1

Read and clean the data; retain line, station, name, station latitude /
longitude, routes served, entry, vending, entrance type, and ADA
compliance. Convert the entry variable from character (YES vs NO) to a
logical variable (the ifelse or case_match function may be useful).

``` r
stations_data = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
  col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

- This data is not tidy. To tidy up the data, I first load the
  NYC_Transit_Subway_Entrance_And_Exit_Data.csv file. I specify that
  `Route` columns 8-11 should be character for consistency with 1-7.
  This dataset contain varibles like: division, Line, Station_name,
  Station_latitude, Station_longitude, Route1 to Route 11,
  Entrance_type, Entry, Exit Only, Vending, staffing, staff_hours, ADA,
  ADA_notes, Free_crossover, north_south_street, east_west_street,
  corner, entry_latitude, entrance_longitude, station_location and
  entrance_loctaion. Then I use `janitor` and `select` to chose those
  columns that I am interested. Also convert the entry variable from
  character `yes` vs `no` to logical variable `true` and `false`. There
  are 1868 rows and 20 columns of the resulting dataset.

``` r
stations_data %>%  
  select(station_name, line) %>%  
  distinct()
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # ℹ 455 more rows

- There are 465 distinct stations.

``` r
stations_data %>%  
  filter(ada == TRUE) %>%  
  select(station_name, line) %>%  
  distinct()
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # ℹ 74 more rows

- There are 84 stations are ADA compliant.

``` r
stations_data %>%  
  filter(vending == "NO") %>% 
  pull(entry) %>%  
  mean()
```

    ## [1] 0.3770492

- There is 0.3770492 of station entrances / exits without vening allow
  entrance.

``` r
stations_data %>%  
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>%  
  select(station_name, line) %>% 
  distinct()
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # ℹ 50 more rows

``` r
stations_data %>%  
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>%  
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>%  
  distinct()
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

- There are 60 distinct stations serve the A train.
- Of the stations that serve the A train, 17 are ADA compliant.

## Problem 2

Read and clean the Mr. Trash Wheel sheet:

specify the sheet in the Excel file and to omit non-data entries (rows
with notes / figures; columns containing notes) using arguments in
read_excel use reasonable variable names omit rows that do not include
dumpster-specific data round the number of sports balls to the nearest
integer and converts the result to an integer variable (using
`as.integer`)

``` r
Trash_data = "./data/202409 Trash Wheel Collection Data.xlsx"

Mr_Trash_Wheel = 
  read_excel(Trash_data, sheet = "Mr. Trash Wheel", range = "A2:N653") |> 
  janitor::clean_names() |>
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    year = as.double(year),
    Trash_Wheel = "Mr"
  )

Prof_Trash_Wheel = 
  read_excel(Trash_data, sheet = "Professor Trash Wheel", range = "A2:M120") |>
  janitor::clean_names() |>
  mutate(
    Trash_Wheel = "Prof"
    )

Gwynnda_Trash_Wheel = 
  read_excel(Trash_data, sheet = "Gwynnda Trash Wheel", range="A2:L265") |>
  janitor::clean_names() |>
  mutate(
    Trash_Wheel = "Gwynnda"
    )

combined_q2=bind_rows(Mr_Trash_Wheel,Prof_Trash_Wheel,Gwynnda_Trash_Wheel)
```

For `Mr_Trash_Wheel`, extract “Mr. Trash Wheel” from the excel, select
range A2 to N653. Mutate `sports balls` in to interger and round them.
Convert `year` from character to double. The dataset `Mr. Trash Wheel`
has 651 observations and 15 variables.

For `Prof_Trash_Wheel`, extract “Professor Trash Wheel” from the excel,
select range A2 to M120. The dataset `Professor Trash Wheel` has 118
observations and 14 variables.

For `Gwynnda_Trash_Wheel`, extract “Gwynnda Trash Wheel” from the excel,
select range A2 to L265. The dataset `Gwynnda Trash Wheel` has 263
observations and 13 variables.

The combined data of these three datasets `combined_q2` has 1032
observations and 15 variables. The combined dataset contains variable
`dumpster` which indicates the number of dumpster and variables “year”,
“month”, “date” and “weight_tons” etc.

The total weight of trash collected by Professor Trash Wheel is: 246.74,
the total number of cigarette butts collected by Gwynnda in June of 2022
is: 1.812^{4}.

## Problem 3

``` r
Bakers = 
  read_csv("./data/gbb_datasets/bakers.csv") |>
  janitor::clean_names() |>
  separate(baker_name, into = c("baker", "last_name"), sep = " ") |>
  relocate(series)
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
Bakes = 
  read_csv("./data/gbb_datasets/bakes.csv") |>
  janitor::clean_names()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
Results = 
  read_csv("./data/gbb_datasets/results.csv", skip = 2) |>
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
anti = anti_join(Bakes, Results, by = c("series","episode","baker"))

bakes_results = full_join(Results, Bakes, by = c("series","episode","baker")) 
GBBO = 
left_join(bakes_results, Bakers, by = c("series", "baker")) |>
  arrange(series, episode)

write_csv(GBBO, "./data/GBBO.csv")
```

For `Bakers`, load the csv file and clean_name. Because the name of
baker contain both first name and last name in one cell, I separate the
first name into “baker” and last name into “last_name”. Then, relocate
“bakers” to the first column. The dataset `Bakers` has 120 observations
and 6 variables.

For `Bakes`, load the csv file and clean_name. The dataset `Bakes` has
548 observations and 5 variables

For `Results`, load the csv file, skip the first two row that contain
non-related information, then clean_name. the dataset `Results` has 1136
observations and 5 variables.

Use anti_join to check for completeness and correctness across datasets.

full join `Bakers` and `Bakes` files by “series”, “epidode” and “baker”.
Output dataset as `bakes_results`. Left join `bakes_results` and
`Bakers` by “series” and “baker”. Arrange it by “series” and “episode”.
Output dataset as `GBBO`. The combined dataset of these three datasets
`GBBO` has 1144 observations and 15 variables. The combined dataset
contains variable “series”, “episode”, “baker” and “results”, etc.

Finaly, output `GBBO` to a csv file.

``` r
star_winner = GBBO |>
  filter((result == "WINNER" | result == "STAR BAKER")& series >= 5 & series <= 10) |>
  select(series, episode, baker, result) 
q2_table = as.table(as.matrix(star_winner))
q2_table
```

    ##    series episode baker     result    
    ## A   5      1      Nancy     STAR BAKER
    ## B   5      2      Richard   STAR BAKER
    ## C   5      3      Luis      STAR BAKER
    ## D   5      4      Richard   STAR BAKER
    ## E   5      5      Kate      STAR BAKER
    ## F   5      6      Chetna    STAR BAKER
    ## G   5      7      Richard   STAR BAKER
    ## H   5      8      Richard   STAR BAKER
    ## I   5      9      Richard   STAR BAKER
    ## J   5     10      Nancy     WINNER    
    ## K   6      1      Marie     STAR BAKER
    ## L   6      2      Ian       STAR BAKER
    ## M   6      3      Ian       STAR BAKER
    ## N   6      4      Ian       STAR BAKER
    ## O   6      5      Nadiya    STAR BAKER
    ## P   6      6      Mat       STAR BAKER
    ## Q   6      7      Tamal     STAR BAKER
    ## R   6      8      Nadiya    STAR BAKER
    ## S   6      9      Nadiya    STAR BAKER
    ## T   6     10      Nadiya    WINNER    
    ## U   7      1      Jane      STAR BAKER
    ## V   7      2      Candice   STAR BAKER
    ## W   7      3      Tom       STAR BAKER
    ## X   7      4      Benjamina STAR BAKER
    ## Y   7      5      Candice   STAR BAKER
    ## Z   7      6      Tom       STAR BAKER
    ## A1  7      7      Andrew    STAR BAKER
    ## B1  7      8      Candice   STAR BAKER
    ## C1  7      9      Andrew    STAR BAKER
    ## D1  7     10      Candice   WINNER    
    ## E1  8      1      Steven    STAR BAKER
    ## F1  8      2      Steven    STAR BAKER
    ## G1  8      3      Julia     STAR BAKER
    ## H1  8      4      Kate      STAR BAKER
    ## I1  8      5      Sophie    STAR BAKER
    ## J1  8      6      Liam      STAR BAKER
    ## K1  8      7      Steven    STAR BAKER
    ## L1  8      8      Stacey    STAR BAKER
    ## M1  8      9      Sophie    STAR BAKER
    ## N1  8     10      Sophie    WINNER    
    ## O1  9      1      Manon     STAR BAKER
    ## P1  9      2      Rahul     STAR BAKER
    ## Q1  9      3      Rahul     STAR BAKER
    ## R1  9      4      Dan       STAR BAKER
    ## S1  9      5      Kim-Joy   STAR BAKER
    ## T1  9      6      Briony    STAR BAKER
    ## U1  9      7      Kim-Joy   STAR BAKER
    ## V1  9      8      Ruby      STAR BAKER
    ## W1  9      9      Ruby      STAR BAKER
    ## X1  9     10      Rahul     WINNER    
    ## Y1 10      1      Michelle  STAR BAKER
    ## Z1 10      2      Alice     STAR BAKER
    ## A2 10      3      Michael   STAR BAKER
    ## B2 10      4      Steph     STAR BAKER
    ## C2 10      5      Steph     STAR BAKER
    ## D2 10      6      Steph     STAR BAKER
    ## E2 10      7      Henry     STAR BAKER
    ## F2 10      8      Steph     STAR BAKER
    ## G2 10      9      Alice     STAR BAKER
    ## H2 10     10      David     WINNER

There were no predictable result for the final winner. Some person won
“star baker” many times but didn’t won the final “winner”, and some
person didn’t won “star barker” on previous episode, but won the
“winner” at the end.

``` r
Viewers = read_csv("./data/gbb_datasets/viewers.csv") |>
  janitor::clean_names()|>
  head(10)
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
average_series1 = mean(pull(Viewers, series_1), na.rm = TRUE)
average_series5 = mean(pull(Viewers, series_5))
```

Load the csv file, clean_name and use “head(10)” to show first 10 rows.

The average viewership in Season 1 is 2.77. The average viewership in
Season 5 is 10.0393.

\`\`\`
